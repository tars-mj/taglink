# ADR 003.1: Sprint 3 - Migration from Asynchronous to Synchronous Scraping

**Status:** Implemented
**Date:** 2025-11-03
**Decision Makers:** Development Team

## Context

After implementing asynchronous scraping in Sprint 3 (ADR 003), we encountered a critical issue with Next.js 15's `revalidatePath` function when called from background processes. The error indicated that `revalidatePath` cannot be used during render phases or in cached functions, which occurs when called from fire-and-forget async functions.

**Error encountered:**
```
Error: Route /dashboard used "revalidatePath /dashboard" during render which is unsupported.
To ensure revalidation is performed consistently it must always happen outside of renders and cached functions.
```

## Decision

Migrate from asynchronous (fire-and-forget) scraping to synchronous scraping where:
1. User waits for scraping to complete during link creation
2. Full metadata is fetched before saving to database
3. Link is saved with complete information in one transaction

## Implementation Changes

### 1. Server Actions (`src/app/actions/links.ts`)

**Removed:**
- `processLinkScraping` function (async background processor)
- Fire-and-forget pattern with `.catch()`
- Status transitions: `pending` → `processing` → `completed`/`failed`

**Added:**
- Synchronous scraping directly in `createLink` action
- Immediate scraping with 30-second timeout
- Single database insert with complete metadata
- Direct error handling without status updates

### 2. UI Components

**Add Link Dialog (`src/components/links/add-link-dialog.tsx`):**
- Changed loading message: "Adding..." → "Fetching metadata..."
- Updated description to set user expectations about wait time
- Changed success toast to indicate complete metadata fetching

**Dashboard (`src/app/dashboard/page.tsx`):**
- Removed `pending` and `processing` status displays
- Simplified to only show `completed` or `failed` states
- Links now appear with full data immediately

### 3. Database Schema

No migration required - existing fields are reused:
- `ai_processing_status`: Now only uses `completed` or `failed`
- `ai_processing_started_at`: Set at scraping start
- `ai_processing_completed_at`: Set immediately after scraping
- `ai_processing_error`: Populated if scraping fails

Unused states (`pending`, `processing`) remain in schema for backward compatibility.

## Consequences

### Positive

✅ **No more revalidatePath errors** - Synchronous execution avoids render context issues
✅ **Simpler code** - Removed complex async state management
✅ **Immediate feedback** - User sees final result right away
✅ **Better error handling** - Errors reported directly to user
✅ **Easier debugging** - Linear execution flow
✅ **Data consistency** - Link and metadata saved atomically

### Negative

❌ **Longer wait times** - User waits 5-10 seconds during add
❌ **Blocked UI** - Interface frozen during scraping
❌ **Perceived slowness** - App feels less responsive
❌ **Timeout risk** - 30-second operations may frustrate users
❌ **No parallel operations** - Can't add multiple links quickly

## Performance Metrics

**Before (Async):**
- Time to see link in list: <1 second
- Time to complete metadata: 5-10 seconds (background)
- User can add multiple links rapidly

**After (Sync):**
- Time to see link in list: 5-10 seconds
- Time to complete metadata: Immediate (already fetched)
- User must wait between adding links

## Alternatives Considered

### 1. Queue System (BullMQ + Redis)
**Rejected:** Too complex for MVP, requires additional infrastructure

### 2. Edge Functions
**Rejected:** Deployment complexity, still has revalidation issues

### 3. Polling/WebSockets for Updates
**Rejected:** Requires real-time infrastructure, complex state management

### 4. Keep Async, Remove revalidatePath
**Rejected:** Dashboard wouldn't update automatically, poor UX

## Migration Path

### From Async to Sync

1. **Code changes:**
   - Remove background processing function
   - Integrate scraping into main action
   - Simplify status handling

2. **User communication:**
   - Update UI messages to set expectations
   - Add loading indicators
   - Provide clear error messages

3. **Rollback plan:**
   - Git history preserves async implementation
   - Can revert if sync proves too slow
   - Consider queue system for future

## Lessons Learned

1. **Next.js 15 Constraints:** Server Actions have specific execution contexts that limit background operations

2. **UX Trade-offs:** Sometimes "slower but reliable" beats "fast but complex"

3. **MVP Philosophy:** Simpler solutions often better for initial release

4. **Technical Debt:** Async scraping can be reintroduced with proper infrastructure later

## Future Considerations

If synchronous scraping proves too slow:
1. Implement proper job queue (BullMQ/Redis)
2. Use Vercel Functions or similar for background jobs
3. Consider webhooks for scraping completion
4. Implement optimistic UI updates

## References

- [Original Sprint 3 ADR](003-sprint-3-web-scraping.md)
- [Next.js 15 Server Actions Documentation](https://nextjs.org/docs/app/building-your-application/data-fetching/server-actions-and-mutations)
- [Next.js revalidatePath constraints](https://nextjs.org/docs/app/building-your-application/rendering/static-and-dynamic#dynamic-rendering)

---

**Related ADRs:**
- [ADR 003: Sprint 3 - Web Scraping](003-sprint-3-web-scraping.md)

**Impact:** This change affects the core link creation flow and user experience but maintains data integrity and system reliability.